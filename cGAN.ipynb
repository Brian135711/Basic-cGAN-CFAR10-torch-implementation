{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1B1RjIDAT_Vl-EbcIJv6GTy6eJtz1_AeJ","timestamp":1708085168767}],"machine_shape":"hm","gpuType":"V100","mount_file_id":"1nBwlvKxDeyk9Am0vt4p3eSQDCE95IXtG","authorship_tag":"ABX9TyOM7Tdb9F8kGcptPyIiyfvo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":16,"metadata":{"id":"a5ExDL1QswZT","executionInfo":{"status":"ok","timestamp":1708259622545,"user_tz":300,"elapsed":811,"user":{"displayName":"Brian Young","userId":"12917868014324564154"}}},"outputs":[],"source":["import cv2\n","#import mediapipe as mp\n","import numpy as np\n","import time\n","from shapely import Point, Polygon\n","import pandas as pd\n","from PIL import Image, ImageChops\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","import torchvision\n","from torchvision import transforms\n","from torchvision.datasets import CIFAR10"]},{"cell_type":"code","source":["#set gpu for execution\n","device = torch.device('cuda')\n"],"metadata":{"id":"MZX9xf6-tbmH","executionInfo":{"status":"ok","timestamp":1708259626365,"user_tz":300,"elapsed":826,"user":{"displayName":"Brian Young","userId":"12917868014324564154"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["class Discriminator(nn.Module):\n","    def __init__(self, embeddings, nc=3, ndf=64):\n","        super(Discriminator, self).__init__()\n","\n","        self.embeddings = embeddings\n","        self.label_to_image = nn.Linear(100,64*64*3)\n","        self.conv1 = nn.Conv2d(nc * 2, nc, 1, 1, 0, bias=False)\n","\n","        self.main = nn.Sequential(\n","            # input is (nc) x 64 x 64\n","            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. (ndf) x 32 x 32\n","            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. (ndf*2) x 16 x 16\n","            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. (ndf*4) x 8 x 8\n","            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. (ndf*8) x 4 x 4\n","            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x, label_embed):\n","        x = x.view(-1,3,64,64)\n","        label_embed = self.embeddings(label_embed)\n","\n","        label_map = self.label_to_image(label_embed)\n","        label_map = label_map.view(-1,3,64,64)\n","\n","        x = torch.cat([x,label_map], dim=1)\n","\n","        out = self.conv1(x)\n","        output = self.main(out)\n","\n","        return output"],"metadata":{"id":"kealrtMCKxEc","executionInfo":{"status":"ok","timestamp":1708259628455,"user_tz":300,"elapsed":287,"user":{"displayName":"Brian Young","userId":"12917868014324564154"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["class Generator(nn.Module):\n","    def __init__(self, embeddings, nc=3, nz=100, ngf=64):\n","        super(Generator, self).__init__()\n","\n","        self.embeddings = embeddings\n","        self.linear = nn.Linear(200,100)\n","\n","        self.main = nn.Sequential(\n","            # input is Z, going into a convolution\n","            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),\n","            nn.BatchNorm2d(ngf * 8),\n","            nn.ReLU(True),\n","            # state size. (ngf*8) x 4 x 4\n","            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 4),\n","            nn.ReLU(True),\n","            # state size. (ngf*4) x 8 x 8\n","            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 2),\n","            nn.ReLU(True),\n","            # state size. (ngf*2) x 16 x 16\n","            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf),\n","            nn.ReLU(True),\n","            # state size. (ngf) x 32 x 32\n","            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n","            nn.Tanh()\n","            # state size. (nc) x 64 x 64\n","        )\n","\n","    def forward(self, x, label_embed):\n","        x = x.view(-1,nz,1,1)\n","        label_embed = self.embeddings(label_embed)\n","\n","        x = x.view(-1,100)\n","        print(f'label_embed shape', label_embed.shape)\n","        print(f'x shape', x.shape)\n","        x = torch.cat([x,label_embed], dim=1)\n","\n","        x = self.linear(x)\n","        x = x.unsqueeze(2).unsqueeze(3)\n","\n","        output = self.main(x)\n","        return output"],"metadata":{"id":"BQr5A1CALQ37","executionInfo":{"status":"ok","timestamp":1708264784494,"user_tz":300,"elapsed":985,"user":{"displayName":"Brian Young","userId":"12917868014324564154"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["batchsize = 200\n","epochs = 500\n","\n","#Use the CFAR10 dataset\n","from torchvision.datasets import CIFAR10\n","from torchvision.transforms import ToTensor\n","from torch.utils.data import random_split\n","from torchvision import transforms\n","\n","# Define the dataset\n","transform = transforms.Compose([\n","    transforms.Resize(64),\n","    transforms.CenterCrop(64),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","train_data = CIFAR10(root='data/', download=True, transform=transform)\n","txt_label = train_data.classes\n","print(txt_label)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dWK7NX9cNRMe","executionInfo":{"status":"ok","timestamp":1708259640091,"user_tz":300,"elapsed":1535,"user":{"displayName":"Brian Young","userId":"12917868014324564154"}},"outputId":"c6dd50d3-5f2a-4677-b572-c3a88f1e3711"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"]}]},{"cell_type":"code","source":["train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batchsize,shuffle=True,drop_last=True)\n","\n"],"metadata":{"id":"YLBCcb3KNzg6","executionInfo":{"status":"ok","timestamp":1708259644020,"user_tz":300,"elapsed":275,"user":{"displayName":"Brian Young","userId":"12917868014324564154"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["embeddings = nn.Embedding(10,100).to(device)\n","embeddings.weight.requires_grad = False\n","\n","netD = Discriminator(embeddings).to(device)\n","netG = Generator(embeddings).to(device)\n","\n","\n","optimizerD = optim.Adam(netD.parameters(),lr=0.0002,betas=(0.5, 0.999))\n","optimizerG = optim.Adam(netG.parameters(),lr=0.0002,betas=(0.5, 0.999))\n","\n","netD.train()\n","netG.train()\n","\n","nz = 100\n","\n","criterion = nn.BCELoss()\n","\n","real_label = torch.ones([batchsize,1], dtype=torch.float).to(device)\n","fake_label = torch.zeros([batchsize,1], dtype=torch.float).to(device)\n","\n","\n","for epoch in range(epochs):\n","    for i, (input_sequence, label) in enumerate(train_data_loader):\n","\n","        fixed_noise = torch.randn(batchsize, nz, 1, 1, device=device)\n","\n","        input_sequence = input_sequence.to(device)\n","        label_embed = label.to(device)\n","\n","        '''\n","            Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","        '''\n","\n","        D_real_result = netD(input_sequence, label_embed).to(device)\n","        D_real_loss = criterion(D_real_result.view(batchsize,-1), real_label)\n","\n","        G_result = netG(fixed_noise,label_embed)\n","\n","        D_fake_result = netD(G_result,label_embed)\n","\n","        D_fake_loss = criterion(D_fake_result.view(batchsize,-1), fake_label)\n","\n","        # Back propagation\n","        D_train_loss = (D_real_loss + D_fake_loss) / 2\n","\n","        netD.zero_grad()\n","        D_train_loss.backward()\n","        optimizerD.step()\n","\n","        '''\n","            Update G network: maximize log(D(G(z)))\n","        '''\n","        new_label = torch.LongTensor(batchsize,10).random_(0, 10).to(device)\n","        new_embed = new_label[:,0].view(-1)\n","\n","        G_result = netG(fixed_noise, new_embed)\n","\n","        D_fake_result = netD(G_result, new_embed)\n","        G_train_loss = criterion(D_fake_result.view(batchsize,-1), real_label)\n","\n","\n","        # Back propagation\n","        netD.zero_grad()\n","        netG.zero_grad()\n","        G_train_loss.backward()\n","        optimizerG.step()\n","\n","        print(\"D_loss:%f\\tG_loss:%f\" % (D_train_loss,G_train_loss))\n","        #show a generated image on every 25th epoch then close it after 5 seconds\n","\n","        if epoch % 25 == 0:\n","            G_result = netG(fixed_noise, new_embed)\n","            G_result = G_result.cpu().detach().numpy()\n","            plt.imshow(G_result[0].transpose(1,2,0))\n","            plt.show()\n","            plt.close()\n","            time.sleep(5)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1ZkbKclpoUg2upEa7Be5pRWhPF-lVxEA7"},"id":"qPdsK0voLmlA","executionInfo":{"status":"error","timestamp":1708276429921,"user_tz":300,"elapsed":1042800,"user":{"displayName":"Brian Young","userId":"12917868014324564154"}},"outputId":"61c5d23f-1da0-4b6e-96e6-996ac781bc7d"},"execution_count":82,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["#save model and checkpoints then load again to resume training\n","torch.save(netG.state_dict(), 'netG.pth')\n","torch.save(netD.state_dict(), 'netD.pth')\n","torch.save(embeddings.state_dict(), 'embeddings.pth')\n","\n","netG.load_state_dict(torch.load('netG.pth'))\n","netD.load_state_dict(torch.load('netD.pth'))\n","embeddings.load_state_dict(torch.load('embeddings.pth'))\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"mzFGCpHVUHiW","executionInfo":{"status":"ok","timestamp":1708276514579,"user_tz":300,"elapsed":834,"user":{"displayName":"Brian Young","userId":"12917868014324564154"}},"outputId":"eb22920e-32cf-484d-a2b8-b54593c01b29","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":83,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":83}]}]}