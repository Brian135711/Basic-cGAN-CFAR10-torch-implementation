This is a basic implementation of a conditional generative adversarial network (cGAN) to facilitate learning for both me and an opportunity for anyone who would like contribute. A generator generates images based on random noise as a normal GAN, but also takes in a vector of 10 class labels from the CFAR10 dataset ['horse', 'dog', ..., 'cat']. These labels are converted into an imbedding before insertion into the generator and discriminator.  The discriminator judges real or fake and updates weights of the generator as a normal GAN except the idea is that learning and generation can be controlled by these labels as opposed to a normal GAN where the user has no control over what type of image is generated. Here is a link to the original paper Conditional Generative Adversarial Nets by Mirza, and Osindero https://arxiv.org/abs/1411.1784

