This is a basic implementation of a conditional generative adversarial network (cGAN) to facilitate learning for both me and an opportunity for anyone who would like to demonstrate a high degree of expertise in the field of generative AI. All credit will go to those who contribute significantly. A generator generates images based on random noise as a normal GAN, but also takes in a vector of 10 class labels from the CFAR10 dataset ['horse', 'dog', ..., 'cat']. These labels are converted to [0, 1, ..., 10] before insertion into the generator.  The discriminator judges real or fake and updates weights of the generator as a normal GAN except the idea is that learning and generation can be controlled by these labels as opposed to a normal GAN where the user has no control over what type of image is generated.  

As a side note, I am working on a paper while attending the US Army War College that will discuss the current methods of deepfake production and detection methods. I have produced a pretty good SFW deepfake video using two well regarded methods in python and will submit my best version at the end of March along with a paper. If you are a leading expert in this field and would like to contribute I would certainly be very happy to hear from you!

